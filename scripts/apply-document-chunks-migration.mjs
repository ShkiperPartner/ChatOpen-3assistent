import { createClient } from '@supabase/supabase-js';
import { readFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import dotenv from 'dotenv';

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const supabase = createClient(
  process.env.VITE_SUPABASE_URL,
  process.env.VITE_SUPABASE_ANON_KEY
);

console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
console.log('  DOCUMENT_CHUNKS MIGRATION - Apply Missing Columns');
console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

// Read migration file
const migrationPath = join(__dirname, '../supabase/migrations/20250229000003_add_document_chunks_columns.sql');
const migrationSQL = readFileSync(migrationPath, 'utf8');

console.log('ğŸ“„ Migration file:', migrationPath);
console.log('ğŸ“Š Migration size:', migrationSQL.length, 'bytes\n');

// Split into individual statements
const statements = migrationSQL
  .split(';')
  .map(s => s.trim())
  .filter(s => s && !s.startsWith('--'));

console.log(`ğŸ”§ Found ${statements.length} SQL statements\n`);

// Apply each statement
for (let i = 0; i < statements.length; i++) {
  const stmt = statements[i];
  console.log(`\nâ”â”â” Statement ${i + 1}/${statements.length} â”â”â”`);
  console.log(stmt.substring(0, 100) + (stmt.length > 100 ? '...' : ''));

  try {
    const { data, error } = await supabase.rpc('exec_sql', { sql: stmt });

    if (error) {
      console.log('âŒ Error:', error.message);
      if (error.message.includes('already exists') || error.message.includes('duplicate')) {
        console.log('âš ï¸  Column/index already exists - skipping');
      } else {
        throw error;
      }
    } else {
      console.log('âœ… Success');
    }
  } catch (err) {
    console.log('âŒ Failed:', err.message);
    // Continue with other statements
  }
}

console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
console.log('  âœ… MIGRATION COMPLETED');
console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

// Verify structure
console.log('ğŸ” Verifying table structure...\n');
const { data: columns, error: colError } = await supabase.rpc('exec_sql', {
  sql: `
    SELECT column_name, data_type, is_nullable
    FROM information_schema.columns
    WHERE table_name = 'document_chunks'
    ORDER BY ordinal_position;
  `
});

if (columns && columns.length > 0) {
  console.log('âœ… document_chunks columns:');
  console.table(columns);
} else if (colError) {
  console.log('âš ï¸  Could not verify structure:', colError.message);
}

console.log('\nâœ… Ready for testing!\n');
